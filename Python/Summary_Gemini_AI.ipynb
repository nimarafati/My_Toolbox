{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is summary of Gemini course held by Kaggle.  \n",
    "\n",
    "First go to [AI Studio](https://aistudio.google.com/app/apikey) and save API KEY locally in a file (`.env`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=your_actual_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you install SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -q \"google-generativeai>=0.8.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing SDK you are ready to load:\n",
    "- necessary packages \n",
    "- load API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import HTML, Markdown, display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API_KEY environment variable\n",
    "api_key = os.environ.get('API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "flash = genai.GenerativeModel(model_name='gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try your first question from Gemini!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you have a super smart puppy.  You teach it tricks, like \"sit\" and \"fetch\".  At first, the puppy doesn't know what those words mean, but you show it, and it learns!\n",
      "\n",
      "AI is kind of like that super smart puppy, but instead of learning tricks, it learns from information.  We give it lots and lots of information – like pictures of cats and dogs, or stories, or even numbers – and it learns to recognize patterns and make decisions based on that information.\n",
      "\n",
      "So, if you show an AI lots of pictures of cats, it will learn what a cat looks like and can then tell you if a new picture is a cat or not.  It's not actually *thinking* like you or me, but it's getting really good at following instructions and solving problems using the information it's been given.\n",
      "\n",
      "Some AIs are simple, like that puppy learning basic tricks. Others are super complex and can do amazing things, like helping doctors diagnose illnesses or recommending your favorite movies!  It's all about learning from information and getting better at tasks over time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flash = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = flash.generate_content(\"Explain AI to me like I'm a kid.\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start a chat by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = flash.start_chat(history=[])\n",
    "response = chat.send_message('Hello! My name is Zlork.')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out list of models available in Gemini ([Read more here](https://ai.google.dev/gemini-api/docs/models/gemini))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in genai.list_models():\n",
    "  print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[model overview page](https://ai.google.dev/gemini-api/docs/models/gemini)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Q&A with RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs have two limitations:\n",
    "Knowledge is limited to the trained data: Language models are trained on large datasets but cannot dynamically learn or adapt to new information. This means their knowledge might be incomplete or outdated, especially for niche or rapidly evolving topics.\n",
    "\n",
    "Input limitations: Models can only respond based on the input provided at the moment, constrained by token limits and lacking the ability to integrate external data dynamically during the interaction.\n",
    "\n",
    "To address these limitations, Retrieval-Augmented Generation (RAG) combines the power of LLMs with a retrieval mechanism to access and integrate external knowledge dynamically. RAG works in three key steps:\n",
    "\n",
    "1. Indexing  \n",
    "The process begins by creating an index of the external knowledge source. This source can include structured or unstructured data such as:\n",
    "- Documents  \n",
    "- Databases  \n",
    "- Research papers  \n",
    "- Knowledge graphs  \n",
    "- Websites  \n",
    "Tools like vector databases (e.g., Qdrant, Pinecone, ChromaDB, or FAISS) are used to convert text into embeddings—a numerical representation of semantic meaning. These embeddings are indexed to enable fast and efficient searches based on relevance.  \n",
    "2. Retrieval  \n",
    "When a query is received, the system uses the indexed embeddings to find the most relevant pieces of information from the knowledge base.  \n",
    "Retrieval involves matching the query with stored embeddings using similarity metrics (e.g., cosine similarity). This step ensures the model has access to contextually appropriate information that may not be part of its trained data.  \n",
    "Retrieved information is then passed to the language model as supplementary context.\n",
    "3. Generation  \n",
    "The language model generates a response by combining its inherent knowledge with the retrieved external data.  \n",
    "The retrieved content acts as an extension of the model’s training, enhancing its output with up-to-date and specific information tailored to the query.  \n",
    "This hybrid approach enables the model to produce factually accurate and context-aware responses, addressing the limitations of training data and input constraints.  \n",
    "Why Use RAG? RAG enhances the utility of LLMs in applications such as:  \n",
    "\n",
    "- Dynamic question-answering systems  \n",
    "- Personalized recommendations  \n",
    "- Interactive data exploration  \n",
    "- Research and analysis tools  \n",
    "- Real-time customer support  \n",
    "\n",
    "This combination of retrieval and generation creates a powerful framework for overcoming the inherent limitations of standalone LLMs.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We creat embedding by `ChromaDB` model and then use it to generate content by `gemini-1.5-flash` model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q \"google-generativeai>=0.8.3\" chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The data consists of three documents (with text) we create a three variables and a list referring to these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT1 = \"Operating the Climate Control System  Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"\n",
    "DOCUMENT2 = 'Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.'\n",
    "DOCUMENT3 = \"Shifting Gears Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"\n",
    "\n",
    "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select `text-embedding-004`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    \"\"\"ArithmeticError\n",
    "    Embedding function that uses the Google AI text embedding API to generate embeddings for documents or queries.\n",
    "    \n",
    "    Args:\n",
    "        document_mode: Whether to generate embeddings for documents (True) or queries (False).\n",
    "\n",
    "    Returns:\n",
    "        Embeddings: The embeddings generated by the API.\n",
    "\n",
    "    \"\"\"\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    document_mode = True\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings: \n",
    "        # Determine the embedding task based on the document_mode\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        # Specify the retry policy for the API request\n",
    "        # Retry on transient errors\n",
    "        # See https://googleapis.dev/python/google-api-core/latest/retry.html\n",
    "        \n",
    "        retry_policy = {\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n",
    "\n",
    "        # Generate embeddings using the Google AI text embedding API\n",
    "        response = genai.embed_content(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            content=input,\n",
    "            task_type=embedding_task,\n",
    "            request_options=retry_policy,\n",
    "        )\n",
    "        return response[\"embedding\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following code creates a vector database collection named \"googlecardb\" using ChromaDB. It defines an embedding function, enables document mode, and adds documents to the collection with unique IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# Create a new collection in ChromaDB\n",
    "DB_NAME = \"googlecardb\" \n",
    "embed_fn = GeminiEmbeddingFunction() # Create an instance of the embedding function\n",
    "embed_fn.document_mode = True # Set the document_mode to True\n",
    "\n",
    "chroma_client = chromadb.Client() # Create a new ChromaDB client\n",
    "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
    "# Add the documents to the collection\n",
    "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval \n",
    "To search the database we switch to query mode.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch to query mode when generating embeddings.\n",
    "embed_fn.document_mode = False\n",
    "\n",
    "# Search the Chroma DB using the specified query.\n",
    "query = \"How do you use the touchscreen to play music?\"\n",
    "\n",
    "result = db.query(query_texts=[query], n_results=1)\n",
    "[[passage]] = result[\"documents\"]\n",
    "\n",
    "Markdown(passage) # Display the passage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Generation: Providing the Answer  \n",
    "\n",
    "Once you’ve retrieved a relevant passage from the document set (retrieval step), you can create a generation prompt for the Gemini API to generate the final answer. In this example, only one passage was retrieved, but in practice, especially with large datasets, it’s best to retrieve multiple passages and let the Gemini model determine their relevance. It's acceptable if some retrieved passages are not directly related to the question, as the generation step will focus only on the relevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
      "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
      "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
      "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
      "\n",
      "QUESTION: How do you use the touchscreen to play music?\n",
      "PASSAGE: Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \"Navigation\" icon to get directions to your destination or touch the \"Music\" icon to play your favorite songs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "query_oneline = query.replace(\"\\n\", \" \")\n",
    "\n",
    "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
    "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \n",
    "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \n",
    "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \n",
    "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
    "\n",
    "QUESTION: {query_oneline}\n",
    "PASSAGE: {passage_oneline}\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the answer  \n",
    "Now let's generate an answer by `generate_content` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To play music on your Googlecar's touchscreen, simply touch the \"Music\" icon on the main display;  it's that easy!  The touchscreen is the main way you'll interact with many features of your car, including navigation, entertainment (like music), and the climate control settings.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "answer = model.generate_content(prompt)\n",
    "Markdown(answer.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
